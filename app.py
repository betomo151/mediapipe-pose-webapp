import streamlit as st
import mediapipe as mp
import cv2
import tempfile
import os

st.title("MediaPipe Pose å‹•ç”»å‡¦ç† WebApp")

video_file = st.file_uploader("ğŸ¥ å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆ.mp4/.movï¼‰", type=["mp4", "mov"])

if video_file is not None:
    # å‹•ç”»ã‚’ä¸€æ™‚ä¿å­˜
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    tfile.write(video_file.read())
    input_path = tfile.name

    # OpenCVã§å‹•ç”»èª­ã¿è¾¼ã¿
    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        st.error("âŒ å‹•ç”»ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    else:
        st.info("â³ ãƒãƒ¼ã‚ºæ¤œå‡ºå‡¦ç†ä¸­...")

        # å‹•ç”»æƒ…å ±å–å¾—
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)

        # å‡ºåŠ›å…ˆè¨­å®š
        output_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        output_path = output_file.name
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        # MediaPipeåˆæœŸåŒ–
        mp_pose = mp.solutions.pose
        mp_drawing = mp.solutions.drawing_utils

        with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5) as pose:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(image)

                if results.pose_landmarks:
                    mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

                out.write(frame)

        cap.release()
        out.release()

        st.success("âœ… ãƒãƒ¼ã‚ºæ¤œå‡ºå®Œäº†ï¼ä»¥ä¸‹ã®å‹•ç”»ã§ç¢ºèªã§ãã¾ã™ã€‚")
        st.video(output_path)

        # Cleanup (optional)
        os.remove(input_path)
